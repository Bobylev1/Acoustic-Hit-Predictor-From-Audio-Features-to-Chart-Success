"""
Run Model Module
–ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
"""

import os
import joblib
import pandas as pd
import numpy as np
from sklearn.preprocessing import PolynomialFeatures


def download_model_from_hf(local_path='models/final_random_forest_model.pkl'):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Hugging Face
    
    Args:
        local_path: –õ–æ–∫–∞–ª—å–Ω—ã–π –ø—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    """
    try:
        from huggingface_hub import hf_hub_download
        
        print("‚¨áÔ∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ –ª–æ–∫–∞–ª—å–Ω–æ")
        print("üì• –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å Hugging Face...")
        
        # –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É models, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        downloaded_path = hf_hub_download(
            repo_id="mmobi/Forest_Regressor_v1",
            filename="final_random_forest_model.pkl",
            cache_dir=None,
            local_dir=os.path.dirname(local_path),
            local_dir_use_symlinks=False
        )
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å Hugging Face")
        return local_path
        
    except ImportError:
        raise ImportError(
            "–î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ: pip install huggingface_hub"
        )
    except Exception as e:
        raise RuntimeError(
            f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ —Å Hugging Face: {e}\n"
            f"–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞: –∑–∞–ø—É—Å—Ç–∏—Ç–µ python run_optimization.py"
        )


def load_model(model_path='../models/final_random_forest_model.pkl'):
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ (–ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ —Å Hugging Face)
    
    Args:
        model_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
        
    Returns:
        –ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
    """
    # –ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –ø—É—Ç–∏
    alt_paths = [
        model_path,
        'models/final_random_forest_model.pkl',
        os.path.join('..', 'models', 'final_random_forest_model.pkl'),
        os.path.join('src', '..', 'models', 'final_random_forest_model.pkl')
    ]
    
    found_path = None
    for alt_path in alt_paths:
        if os.path.exists(alt_path):
            found_path = alt_path
            break
    
    # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞ - –∑–∞–≥—Ä—É–∂–∞–µ–º —Å HF
    if found_path is None:
        found_path = download_model_from_hf('models/final_random_forest_model.pkl')
    
    model = joblib.load(found_path)
    print(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {found_path}")
    return model


def prepare_features(df):
    """
    –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
    –ü–æ–≤—Ç–æ—Ä—è–µ—Ç –ª–æ–≥–∏–∫—É –∏–∑ model_optimization.py
    
    Args:
        df: DataFrame —Å –∏—Å—Ö–æ–¥–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
        
    Returns:
        DataFrame —Å –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
    """
    df_features = df.copy()
    
    # –ë–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    df_features['duration_min'] = df_features['duration_ms'] / 60000
    df_features['energy_dance_ratio'] = df_features['energy'] / (df_features['danceability'] + 1e-6)
    df_features['acoustic_energy_balance'] = df_features['acousticness'] * (1 - df_features['energy'])
    df_features['tempo_energy_product'] = df_features['tempo'] * df_features['energy']
    df_features['valence_energy_interaction'] = df_features['valence'] * df_features['energy']
    
    # –õ–æ–≥–∞—Ä–∏—Ñ–º–∏—á–µ—Å–∫–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏–∏
    df_features['log_duration_ms'] = np.log1p(df_features['duration_ms'])
    df_features['log_instrumentalness'] = np.log1p(df_features['instrumentalness'] * 1e6) / np.log(1e6 + 1)
    df_features['log_speechiness'] = np.log1p(df_features['speechiness'] * 1e6) / np.log(1e6 + 1)
    df_features['log_loudness'] = np.log1p(df_features['loudness'] + 60)
    
    # –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
    df_features['is_high_energy'] = (df_features['energy'] > 0.7).astype(int)
    df_features['is_major_mode'] = df_features['mode'].astype(int)
    df_features['is_high_danceability'] = (df_features['danceability'] > 0.7).astype(int)
    df_features['is_high_valence'] = (df_features['valence'] > 0.7).astype(int)
    
    # –í—Å–µ–≥–¥–∞ —Å–æ–∑–¥–∞–µ–º is_explicit (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0, –µ—Å–ª–∏ –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö)
    if 'explicit' in df_features.columns:
        df_features['is_explicit'] = df_features['explicit'].astype(int)
    else:
        df_features['is_explicit'] = 0
    
    # –ü–æ–ª–∏–Ω–æ–º–∏–∞–ª—å–Ω—ã–µ –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è
    key_features_for_poly = ['danceability', 'valence', 'energy', 'tempo']
    poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)
    poly_features = poly.fit_transform(df_features[key_features_for_poly])
    poly_feature_names = poly.get_feature_names_out(key_features_for_poly)
    
    for feature_name in poly_feature_names:
        if ' ' in feature_name:
            clean_name = feature_name.replace(' ', '_')
            if clean_name not in df_features.columns:
                idx = list(poly_feature_names).index(feature_name)
                df_features[clean_name] = poly_features[:, idx]
    
    # –í—ã–±–∏—Ä–∞–µ–º –Ω—É–∂–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
    numeric_features = df_features.select_dtypes(include=[np.number]).columns.tolist()
    
    # –ò—Å–∫–ª—é—á–∞–µ–º —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –∏ –Ω–µ–Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏
    exclude_cols = ['popularity', 'track_id', 'key', 'mode', 'time_signature']
    numeric_features = [f for f in numeric_features if f not in exclude_cols]
    
    X = df_features[numeric_features].copy()
    
    # –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤
    if X.isnull().sum().sum() > 0:
        X = X.fillna(X.median())
    
    return X


def predict(model, X):
    """
    –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π
    
    Args:
        model: –û–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å
        X: –ü—Ä–∏–∑–Ω–∞–∫–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        
    Returns:
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    """
    predictions = model.predict(X)
    # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω 0-100
    predictions = np.clip(predictions, 0, 100)
    return predictions


def predict_from_csv(csv_path, model_path='../models/final_random_forest_model.pkl'):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ —Ç—Ä–µ–∫–æ–≤ –∏–∑ CSV —Ñ–∞–π–ª–∞
    
    Args:
        csv_path: –ü—É—Ç—å –∫ CSV —Ñ–∞–π–ª—É —Å –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏ —Ç—Ä–µ–∫–æ–≤
        model_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
        
    Returns:
        DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
    """
    print("="*70)
    print("–ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–ï –ü–û–ü–£–õ–Ø–†–ù–û–°–¢–ò –¢–†–ï–ö–û–í")
    print("="*70)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = load_model(model_path)
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
    print(f"\n–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {csv_path}")
    df = pd.read_csv(csv_path)
    print(f"‚úì –ó–∞–≥—Ä—É–∂–µ–Ω–æ —Ç—Ä–µ–∫–æ–≤: {len(df)}")
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    print("\n–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
    X = prepare_features(df)
    print(f"‚úì –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {X.shape[1]}")
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    print("\n–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π...")
    predictions = predict(model, X)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤ DataFrame
    df['predicted_popularity'] = predictions
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å —Ä–µ–∞–ª—å–Ω–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å, —Å—á–∏—Ç–∞–µ–º –æ—à–∏–±–∫—É
    if 'popularity' in df.columns:
        df['error'] = abs(df['popularity'] - df['predicted_popularity'])
        mean_error = df['error'].mean()
        print(f"\n‚úì –°—Ä–µ–¥–Ω—è—è –∞–±—Å–æ–ª—é—Ç–Ω–∞—è –æ—à–∏–±–∫–∞: {mean_error:.2f}")
    
    print(f"‚úì –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –≤—ã–ø–æ–ª–Ω–µ–Ω—ã –¥–ª—è {len(df)} —Ç—Ä–µ–∫–æ–≤")
    print("\n" + "="*70)
    
    return df


def predict_single_track(track_features, model_path='../models/final_random_forest_model.pkl'):
    """
    –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞
    
    Args:
        track_features: –°–ª–æ–≤–∞—Ä—å —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ —Ç—Ä–µ–∫–∞
        model_path: –ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏
        
    Returns:
        –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å
    """
    # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ —Å–ª–æ–≤–∞—Ä—è
    df = pd.DataFrame([track_features])
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
    model = load_model(model_path)
    
    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    X = prepare_features(df)
    
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
    prediction = predict(model, X)[0]
    
    return prediction


def show_top_predictions(df, n=10):
    """
    –ü–æ–∫–∞–∑–∞—Ç—å —Ç–æ–ø-N —Ç—Ä–µ–∫–æ–≤ –ø–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–æ–π –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç–∏
    
    Args:
        df: DataFrame —Å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è–º–∏
        n: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç—Ä–µ–∫–æ–≤ –¥–ª—è –ø–æ–∫–∞–∑–∞
    """
    print(f"\n–¢–û–ü-{n} –¢–†–ï–ö–û–í –ü–û –ü–†–ï–î–°–ö–ê–ó–ê–ù–ù–û–ô –ü–û–ü–£–õ–Ø–†–ù–û–°–¢–ò:")
    print("="*70)
    
    top_tracks = df.nlargest(n, 'predicted_popularity')
    
    for idx, (i, row) in enumerate(top_tracks.iterrows(), 1):
        print(f"\n{idx}. –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: {row['predicted_popularity']:.1f}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç—Ä–µ–∫–∞, –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'track_name' in df.columns:
            print(f"   –¢—Ä–µ–∫: {row['track_name']}")
        if 'artist_name' in df.columns:
            print(f"   –ò—Å–ø–æ–ª–Ω–∏—Ç–µ–ª—å: {row['artist_name']}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω—É—é –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –µ—Å—Ç—å
        if 'popularity' in df.columns:
            print(f"   –†–µ–∞–ª—å–Ω–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: {row['popularity']:.1f}")
            print(f"   –û—à–∏–±–∫–∞: {row['error']:.1f}")
        
        # –ö–ª—é—á–µ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        print(f"   Energy: {row['energy']:.2f}, Danceability: {row['danceability']:.2f}, "
              f"Valence: {row['valence']:.2f}")


def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç—ã
    """
    print("="*70)
    print("ACOUSTIC HIT PREDICTOR - –ó–ê–ü–£–°–ö –ú–û–î–ï–õ–ò")
    print("="*70)
    
    # –ü—Ä–∏–º–µ—Ä 1: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    dataset_path = os.path.join('src', 'dataset', 'dataset.csv')
    if not os.path.exists(dataset_path):
        dataset_path = os.path.join('dataset', 'dataset.csv')
    
    if os.path.exists(dataset_path):
        print("\n1. –ó–∞–≥—Ä—É–∑–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞...")
        df = pd.read_csv(dataset_path, index_col=0)
        
        # –ë–µ—Ä–µ–º —Å–ª—É—á–∞–π–Ω—É—é –≤—ã–±–æ—Ä–∫—É –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
        sample_df = df.sample(n=min(100, len(df)), random_state=42)
        
        print(f"   –í–∑—è—Ç–∞ –≤—ã–±–æ—Ä–∫–∞: {len(sample_df)} —Ç—Ä–µ–∫–æ–≤")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        model = load_model()
        X = prepare_features(sample_df)
        predictions = predict(model, X)
        
        sample_df['predicted_popularity'] = predictions
        if 'popularity' in sample_df.columns:
            sample_df['error'] = abs(sample_df['popularity'] - sample_df['predicted_popularity'])
            print(f"   –°—Ä–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {sample_df['error'].mean():.2f}")
        
        # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ø-10
        show_top_predictions(sample_df, n=10)
    
    # –ü—Ä–∏–º–µ—Ä 2: –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞
    print("\n\n2. –ü—Ä–∏–º–µ—Ä –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç—Ä–µ–∫–∞:")
    print("="*70)
    
    example_track = {
        'duration_ms': 200000,
        'danceability': 0.7,
        'energy': 0.8,
        'loudness': -5.0,
        'speechiness': 0.05,
        'acousticness': 0.1,
        'instrumentalness': 0.0,
        'liveness': 0.1,
        'valence': 0.6,
        'tempo': 120.0,
        'mode': 1,
        'key': 5,
        'time_signature': 4
    }
    
    print("\n–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç—Ä–µ–∫–∞:")
    for key, value in example_track.items():
        print(f"  {key}: {value}")
    
    predicted_popularity = predict_single_track(example_track)
    print(f"\n–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω–∞—è –ø–æ–ø—É–ª—è—Ä–Ω–æ—Å—Ç—å: {predicted_popularity:.1f}/100")
    
    print("\n" + "="*70)
    print("‚úÖ –î–ï–ú–û–ù–°–¢–†–ê–¶–ò–Ø –ó–ê–í–ï–†–®–ï–ù–ê")
    print("="*70)


if __name__ == '__main__':
    main()
